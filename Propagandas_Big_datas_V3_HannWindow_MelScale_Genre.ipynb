{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Calculate and Save Spectrograms\n",
    "\n",
    "    Authors: Fernanda Ferreira and Victor Paganotto\n",
    "    Professor: Tiago F. Tavares\n",
    "    \n",
    "    date: Sept/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display as ld\n",
    "# Printa todos os valores do array\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "np.set_printoptions(threshold=10)\n",
    "import pandas as pd\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "import os\n",
    "import re\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audios(data, n): #1, 0,2 0,5-0,75\n",
    "    len_audios = []\n",
    "    audios = []\n",
    "\n",
    "    for file in data:\n",
    "        #input()\n",
    "        #audio, sr = librosa.core.load(file, sr=22050)\n",
    "        audio, sr = librosa.load(file, sr=22050)\n",
    "        audio = (audio - np.mean(audio))/np.std(audio)\n",
    "        #print (len(audio))\n",
    "        maxN = int(n * sr)\n",
    "        x = audio[0:maxN]\n",
    "        x = (x - np.mean(x)) / np.std(x)\n",
    "        w = np.hanning(len(x))\n",
    "        xw = x * w\n",
    "        audios.append(xw)\n",
    "        len_audios.append(len(xw))\n",
    "        \n",
    "    max_audios = max(len_audios)\n",
    "        \n",
    "    return audios, max_audios\n",
    "\n",
    "#To convert the hop length and frame size to units of seconds:\n",
    "#print (\"hop length[s]:\", float(hop_length)/sr) # units of seconds\n",
    "#print (\"frame size[s]:\",float(n_fft)/sr) # units of seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_specs(audios, max_audios):\n",
    "    specs = []\n",
    "    \n",
    "    for i in range(len(audios)):\n",
    "        i_audio = np.array(audios[i])\n",
    "        i_audio.resize(max_audios)\n",
    "        x = librosa.feature.melspectrogram(y=i_audio, sr=22050, S=None, n_fft=2048, hop_length=1024)\n",
    "        X = np.abs(x)\n",
    "        specs.append(X)\n",
    "        \n",
    "    return specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_elements(seq) -> dict:\n",
    "    \"\"\"Tally elements from `seq`.\"\"\"\n",
    "    hist = {}\n",
    "    for i in seq:\n",
    "        hist[i] = hist.get(i, 0) + 1\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(data):\n",
    "    l = []\n",
    "    for file in data:\n",
    "        (dirname, sname) = os.path.split(file)\n",
    "        (name, ext) = os.path.splitext(sname)\n",
    "        (label, num) = os.path.splitext(name)\n",
    "        n = re.split('-', label, flags=re.IGNORECASE)\n",
    "        n2 = re.split('[0-9]+', n[0], flags=re.IGNORECASE)\n",
    "        if len(n2)<2:\n",
    "            l.append(n2[0])\n",
    "            #print(n2[0])\n",
    "        else:\n",
    "            l.append(n2[1])\n",
    "            #print(n2[1])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "# def string_to_binary(lista):\n",
    "    \n",
    "#     for i in range(len(lista)):\n",
    "#         if lista[i] == 'P':\n",
    "#             lista[i] = 0\n",
    "#         elif lista[i] == 'NP':\n",
    "#             lista[i] = 1\n",
    "#     return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_train, data_test, n):\n",
    "    audios_train, max_audios_train = read_audios(data_train, n)\n",
    "    audios_test, max_audios_test = read_audios(data_test, n)\n",
    "    \n",
    "    if max_audios_train > max_audios_test:\n",
    "        specs_train = my_specs(audios_train, max_audios_train)\n",
    "    else:\n",
    "        specs_train = my_specs(audios_train, max_audios_test)\n",
    "        \n",
    "    if max_audios_train > max_audios_test:\n",
    "        x_test = my_specs(audios_test, max_audios_train)\n",
    "    else:\n",
    "        x_test = my_specs(audios_test, max_audios_test)\n",
    "               \n",
    "    l_train = read_labels(data_train)\n",
    "    y_test = read_labels(data_test)\n",
    "    \n",
    "    l_count_train = count_elements(l_train)\n",
    "    l_count_test = count_elements(y_test)\n",
    "    print('Train:', l_count_train, 'Test:', l_count_test)\n",
    "    \n",
    "    #stratify: certifica a mesma quantidade de audios de cada classe.\n",
    "    x_train, x_val, y_train, y_val = train_test_split(specs_train, l_train, test_size=0.2, stratify=l_train)\n",
    "    \n",
    "    #y_train_bi = string_to_binary(y_train)\n",
    "    #print (y_train_bi)\n",
    "\n",
    "    #y_test_bi = string_to_binary(y_test)\n",
    "    #print (y_test_bi)\n",
    "\n",
    "    #y_val_bi = string_to_binary(y_val)\n",
    "    #print (y_val_bi)\n",
    "    \n",
    "    x_train_np = np.array(x_train)\n",
    "    x_test_np = np.array(x_test)\n",
    "    x_val_np = np.array(x_val)\n",
    "\n",
    "    y_train_np = np.array(y_train)\n",
    "    y_test_np = np.array(y_test)\n",
    "    y_val_np = np.array(y_val)\n",
    "\n",
    "    print (x_train_np.shape, y_train_np.shape)\n",
    "    print (x_test_np.shape, y_test_np.shape)\n",
    "    print(x_val_np.shape, y_val_np.shape)\n",
    "    \n",
    "    return x_train_np, x_test_np, x_val_np, y_train_np, y_test_np, y_val_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "548\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- Completa -----------------------------------\n",
    "# data_train = glob.glob('')\n",
    "# print (len(data_train))\n",
    "# data_test = glob.glob('Novos_testes/Completa/Test/*.mp3')\n",
    "# print (len(data_test))\n",
    "\n",
    "# ------------------------- Trans_trans -----------------------------------\n",
    "# data_train = glob.glob('Novos_testes/T_T/Train/*.mp3')\n",
    "# print (len(data_train))\n",
    "# data_test = glob.glob('Novos_testes/T_T/Test/*.mp3')\n",
    "# print (len(data_test))\n",
    "\n",
    "#-------------------------- NoTrans_trans --------------------------------\n",
    "#data_train = glob.glob('Novos_testes/NT_T/Train/*.mp3')\n",
    "#print (len(data_train))\n",
    "#data_test = glob.glob('Novos_testes/NT_T/Test/*.mp3')\n",
    "#print (len(data_test))\n",
    "\n",
    "#---------------------------- Trans_NoTrans -------------------------------\n",
    "#data_train = glob.glob('Novos_testes/T_NT/Train/*.mp3')\n",
    "#print (len(data_train))\n",
    "#data_test = glob.glob('Novos_testes/T_NT/Test/*.mp3')\n",
    "#print (len(data_test))\n",
    "\n",
    "data_train = glob.glob('Generos/Data_driven/Train/*')\n",
    "print (len(data_train))\n",
    "data_test = glob.glob('Generos/Data_driven/Test/*')\n",
    "print (len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: {'disco': 50, 'pop': 50, 'metal': 50, 'jazz': 50, 'P': 50, 'classical': 50, 'rock': 50, 'hiphop': 50, 'country': 50, 'blues': 50, 'reggae': 50} Test: {'pop': 50, 'disco': 50, 'blues': 50, 'metal': 50, 'reggae': 50, 'jazz': 50, 'rock': 50, 'P': 50, 'country': 50, 'hiphop': 48, 'classical': 50}\n",
      "(440, 128, 216) (440,)\n",
      "(548, 128, 216) (548,)\n",
      "(110, 128, 216) (110,)\n",
      "Train: {'disco': 50, 'pop': 50, 'metal': 50, 'jazz': 50, 'P': 50, 'classical': 50, 'rock': 50, 'hiphop': 50, 'country': 50, 'blues': 50, 'reggae': 50} Test: {'pop': 50, 'disco': 50, 'blues': 50, 'metal': 50, 'reggae': 50, 'jazz': 50, 'rock': 50, 'P': 50, 'country': 50, 'hiphop': 48, 'classical': 50}\n",
      "(440, 128, 108) (440,)\n",
      "(548, 128, 108) (548,)\n",
      "(110, 128, 108) (110,)\n",
      "Train: {'disco': 50, 'pop': 50, 'metal': 50, 'jazz': 50, 'P': 50, 'classical': 50, 'rock': 50, 'hiphop': 50, 'country': 50, 'blues': 50, 'reggae': 50} Test: {'pop': 50, 'disco': 50, 'blues': 50, 'metal': 50, 'reggae': 50, 'jazz': 50, 'rock': 50, 'P': 50, 'country': 50, 'hiphop': 48, 'classical': 50}\n",
      "(440, 128, 44) (440,)\n",
      "(548, 128, 44) (548,)\n",
      "(110, 128, 44) (110,)\n",
      "Train: {'disco': 50, 'pop': 50, 'metal': 50, 'jazz': 50, 'P': 50, 'classical': 50, 'rock': 50, 'hiphop': 50, 'country': 50, 'blues': 50, 'reggae': 50} Test: {'pop': 50, 'disco': 50, 'blues': 50, 'metal': 50, 'reggae': 50, 'jazz': 50, 'rock': 50, 'P': 50, 'country': 50, 'hiphop': 48, 'classical': 50}\n",
      "(440, 128, 22) (440,)\n",
      "(548, 128, 22) (548,)\n",
      "(110, 128, 22) (110,)\n"
     ]
    }
   ],
   "source": [
    "# 1 -> 5seg | 0.2 -> 1seg | 0.75 -> 0.75seg | 0.5 -> 0.5seg\n",
    "N = [10, 5, 2, 1]\n",
    "\n",
    "for n in N:\n",
    "    x_train_np, x_test_np, x_val_np, y_train_np, y_test_np, y_val_np = main(data_train, data_test, n)\n",
    "    \n",
    "    joblib.dump(x_train_np, \"Generos/Data_driven/features/x_train\"+str(n)+\".pkl\")\n",
    "    joblib.dump(x_test_np, \"Generos/Data_driven/features/x_test\"+str(n)+\".pkl\")\n",
    "    joblib.dump(x_val_np, \"Generos/Data_driven/features/x_val\"+str(n)+\".pkl\")\n",
    "    joblib.dump(y_train_np, \"Generos/Data_driven/features/y_train\"+str(n)+\".pkl\")\n",
    "    joblib.dump(y_test_np, \"Generos/Data_driven/features/y_test\"+str(n)+\".pkl\")\n",
    "    joblib.dump(y_val_np, \"Generos/Data_driven/features/y_val\"+str(n)+\".pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Escala_Mel/Data_driven/Completa/05seg/y_val.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------- Completa -------------------------------------------------------------\n",
    "# joblib.dump(x_train_np, \"Escala_Mel/Data_driven/Completa/05seg/x_train.pkl\")\n",
    "# joblib.dump(x_test_np, \"Escala_Mel/Data_driven/Completa/05seg/x_test.pkl\")\n",
    "# joblib.dump(x_val_np, \"Escala_Mel/Data_driven/Completa/05seg/x_val.pkl\")\n",
    "# joblib.dump(y_train_np, \"Escala_Mel/Data_driven/Completa/05seg/y_train.pkl\")\n",
    "# joblib.dump(y_test_np, \"Escala_Mel/Data_driven/Completa/05seg/y_test.pkl\")\n",
    "# joblib.dump(y_val_np, \"Escala_Mel/Data_driven/Completa/05seg/y_val.pkl\")\n",
    "\n",
    "#-------------------- Trans_Trans-------------------------------------------------------------------\n",
    "#joblib.dump(x_train_np, \"Escala_Mel/Data_driven/Trans_Trans/05seg/x_train.pkl\")\n",
    "#joblib.dump(x_test_np, \"Escala_Mel/Data_driven/Trans_Trans/05seg/x_test.pkl\")\n",
    "#joblib.dump(x_val_np, \"Escala_Mel/Data_driven/Trans_Trans/05seg/x_val.pkl\")\n",
    "#joblib.dump(y_train_np, \"Escala_Mel/Data_driven/Trans_Trans/05seg/y_train.pkl\")\n",
    "#joblib.dump(y_test_np, \"Escala_Mel/Data_driven/Trans_Trans/05seg/y_test.pkl\")\n",
    "#joblib.dump(y_val_np, \"Escala_Mel/Data_driven/Trans_Trans/05seg/y_val.pkl\")\n",
    "\n",
    "#-------------------------- NoTrans_trans -------------------------------------------------------------\n",
    "#joblib.dump(x_train_np, \"Escala_Mel/Data_driven/NoTrans_Trans/05seg/x_train.pkl\")\n",
    "#joblib.dump(x_test_np, \"Escala_Mel/Data_driven/NoTrans_Trans/05seg/x_test.pkl\")\n",
    "#joblib.dump(x_val_np, \"Escala_Mel/Data_driven/NoTrans_Trans/05seg/x_val.pkl\")\n",
    "#joblib.dump(y_train_np, \"Escala_Mel/Data_driven/NoTrans_Trans/05seg/y_train.pkl\")\n",
    "#joblib.dump(y_test_np, \"Escala_Mel/Data_driven/NoTrans_Trans/05seg/y_test.pkl\")\n",
    "#joblib.dump(y_val_np, \"Escala_Mel/Data_driven/NoTrans_Trans/05seg/y_val.pkl\")\n",
    "\n",
    "# ---------------------------- Trans_NoTrans --------------------------------------------------------------\n",
    "#joblib.dump(x_train_np, \"Escala_Mel/Data_driven/Trans_NoTrans/05seg/x_train.pkl\")\n",
    "#joblib.dump(x_test_np, \"Escala_Mel/Data_driven/Trans_NoTrans/05seg/x_test.pkl\")\n",
    "#joblib.dump(x_val_np, \"Escala_Mel/Data_driven/Trans_NoTrans/05seg/x_val.pkl\")\n",
    "#joblib.dump(y_train_np, \"Escala_Mel/Data_driven/Trans_NoTrans/05seg/y_train.pkl\")\n",
    "#joblib.dump(y_test_np, \"Escala_Mel/Data_driven/Trans_NoTrans/05seg/y_test.pkl\")\n",
    "#joblib.dump(y_val_np, \"Escala_Mel/Data_driven/Trans_NoTrans/05seg/y_val.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração da matriz Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print (x_train_np.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "Rn = np.random.randn(x_train_np.shape[1], x_train_np.shape[1])\n",
    "#print(Rn)\n",
    "#print(Rn.shape)\n",
    "\n",
    "#joblib.dump(Rn, \"Escala_Mel/Random/Mx_random.pkl\")\n",
    "\n",
    "Rn = joblib.load(\"Escala_Mel/Random/Mx_random.pkl\")\n",
    "print (Rn.shape)\n",
    "\n",
    "# x_train_Rn = np.zeros((x_train_np.shape[0], x_train_np.shape[1], x_train_np.shape[2]))\n",
    "\n",
    "# for i in range(len(x_train_np)):\n",
    "#     x_train_Rn[i][:][:] = np.dot(Rn, x_train_np[i])\n",
    "#     #x_train_mx[i][:] = x_train_np[i] * mx\n",
    "    \n",
    "# print (x_train_Rn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
